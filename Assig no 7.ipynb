{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DS Assig no 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Samiksha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Samiksha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Samiksha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Samiksha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import math\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"\n",
    "The internet has become an integral part of modern life, providing a vast array of information and services at our fingertips. With just a few clicks or taps, we can access news, entertainment, education, communication, and commerce from anywhere in the world. However, the benefits of the internet come with risks as well, such as privacy concerns, cybercrime, misinformation, and addiction. It is important for individuals and organizations to be aware of these risks and to take measures to protect themselves and their data online. By practicing safe online behavior, such as using strong passwords, avoiding suspicious links, and keeping software up-to-date, we can enjoy the benefits of the internet while minimizing the risks\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words : ['The', 'internet', 'has', 'become', 'an', 'integral', 'part', 'of', 'modern', 'life', ',', 'providing', 'a', 'vast', 'array', 'of', 'information', 'and', 'services', 'at', 'our', 'fingertips', '.', 'With', 'just', 'a', 'few', 'clicks', 'or', 'taps', ',', 'we', 'can', 'access', 'news', ',', 'entertainment', ',', 'education', ',', 'communication', ',', 'and', 'commerce', 'from', 'anywhere', 'in', 'the', 'world', '.', 'However', ',', 'the', 'benefits', 'of', 'the', 'internet', 'come', 'with', 'risks', 'as', 'well', ',', 'such', 'as', 'privacy', 'concerns', ',', 'cybercrime', ',', 'misinformation', ',', 'and', 'addiction', '.', 'It', 'is', 'important', 'for', 'individuals', 'and', 'organizations', 'to', 'be', 'aware', 'of', 'these', 'risks', 'and', 'to', 'take', 'measures', 'to', 'protect', 'themselves', 'and', 'their', 'data', 'online', '.', 'By', 'practicing', 'safe', 'online', 'behavior', ',', 'such', 'as', 'using', 'strong', 'passwords', ',', 'avoiding', 'suspicious', 'links', ',', 'and', 'keeping', 'software', 'up-to-date', ',', 'we', 'can', 'enjoy', 'the', 'benefits', 'of', 'the', 'internet', 'while', 'minimizing', 'the', 'risks']\n"
     ]
    }
   ],
   "source": [
    "#tokenization\n",
    "words = word_tokenize(document)\n",
    "print(\"Original words :\", words)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging : [('The', 'DT'), ('internet', 'NN'), ('has', 'VBZ'), ('become', 'VBN'), ('an', 'DT'), ('integral', 'JJ'), ('part', 'NN'), ('of', 'IN'), ('modern', 'JJ'), ('life', 'NN'), (',', ','), ('providing', 'VBG'), ('a', 'DT'), ('vast', 'JJ'), ('array', 'NN'), ('of', 'IN'), ('information', 'NN'), ('and', 'CC'), ('services', 'NNS'), ('at', 'IN'), ('our', 'PRP$'), ('fingertips', 'NNS'), ('.', '.'), ('With', 'IN'), ('just', 'RB'), ('a', 'DT'), ('few', 'JJ'), ('clicks', 'NNS'), ('or', 'CC'), ('taps', 'NNS'), (',', ','), ('we', 'PRP'), ('can', 'MD'), ('access', 'NN'), ('news', 'NN'), (',', ','), ('entertainment', 'NN'), (',', ','), ('education', 'NN'), (',', ','), ('communication', 'NN'), (',', ','), ('and', 'CC'), ('commerce', 'NN'), ('from', 'IN'), ('anywhere', 'RB'), ('in', 'IN'), ('the', 'DT'), ('world', 'NN'), ('.', '.'), ('However', 'RB'), (',', ','), ('the', 'DT'), ('benefits', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('internet', 'NN'), ('come', 'NN'), ('with', 'IN'), ('risks', 'NNS'), ('as', 'RB'), ('well', 'RB'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('privacy', 'NN'), ('concerns', 'NNS'), (',', ','), ('cybercrime', 'NN'), (',', ','), ('misinformation', 'NN'), (',', ','), ('and', 'CC'), ('addiction', 'NN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('important', 'JJ'), ('for', 'IN'), ('individuals', 'NNS'), ('and', 'CC'), ('organizations', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('aware', 'JJ'), ('of', 'IN'), ('these', 'DT'), ('risks', 'NNS'), ('and', 'CC'), ('to', 'TO'), ('take', 'VB'), ('measures', 'NNS'), ('to', 'TO'), ('protect', 'VB'), ('themselves', 'PRP'), ('and', 'CC'), ('their', 'PRP$'), ('data', 'NNS'), ('online', 'NN'), ('.', '.'), ('By', 'IN'), ('practicing', 'VBG'), ('safe', 'JJ'), ('online', 'JJ'), ('behavior', 'NN'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('using', 'VBG'), ('strong', 'JJ'), ('passwords', 'NNS'), (',', ','), ('avoiding', 'VBG'), ('suspicious', 'JJ'), ('links', 'NNS'), (',', ','), ('and', 'CC'), ('keeping', 'VBG'), ('software', 'NN'), ('up-to-date', 'JJ'), (',', ','), ('we', 'PRP'), ('can', 'MD'), ('enjoy', 'VB'), ('the', 'DT'), ('benefits', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('internet', 'NN'), ('while', 'IN'), ('minimizing', 'VBG'), ('the', 'DT'), ('risks', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "#POS tagging\n",
    "pos = pos_tag(words)\n",
    "\n",
    "print(\"POS tagging :\", pos)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words removed : ['The', 'internet', 'become', 'integral', 'part', 'modern', 'life', ',', 'providing', 'vast', 'array', 'information', 'services', 'fingertips', '.', 'With', 'clicks', 'taps', ',', 'access', 'news', ',', 'entertainment', ',', 'education', ',', 'communication', ',', 'commerce', 'anywhere', 'world', '.', 'However', ',', 'benefits', 'internet', 'come', 'risks', 'well', ',', 'privacy', 'concerns', ',', 'cybercrime', ',', 'misinformation', ',', 'addiction', '.', 'It', 'important', 'individuals', 'organizations', 'aware', 'risks', 'take', 'measures', 'protect', 'data', 'online', '.', 'By', 'practicing', 'safe', 'online', 'behavior', ',', 'using', 'strong', 'passwords', ',', 'avoiding', 'suspicious', 'links', ',', 'keeping', 'software', 'up-to-date', ',', 'enjoy', 'benefits', 'internet', 'minimizing', 'risks']\n"
     ]
    }
   ],
   "source": [
    "#stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [w for w in words if not w in stop_words]\n",
    "\n",
    "print(\"Stop words removed :\", filtered_words)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming : ['the', 'internet', 'becom', 'integr', 'part', 'modern', 'life', ',', 'provid', 'vast', 'array', 'inform', 'servic', 'fingertip', '.', 'with', 'click', 'tap', ',', 'access', 'news', ',', 'entertain', ',', 'educ', ',', 'commun', ',', 'commerc', 'anywher', 'world', '.', 'howev', ',', 'benefit', 'internet', 'come', 'risk', 'well', ',', 'privaci', 'concern', ',', 'cybercrim', ',', 'misinform', ',', 'addict', '.', 'it', 'import', 'individu', 'organ', 'awar', 'risk', 'take', 'measur', 'protect', 'data', 'onlin', '.', 'by', 'practic', 'safe', 'onlin', 'behavior', ',', 'use', 'strong', 'password', ',', 'avoid', 'suspici', 'link', ',', 'keep', 'softwar', 'up-to-d', ',', 'enjoy', 'benefit', 'internet', 'minim', 'risk']\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "print(\"Stemming :\", stemmed_words)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization : ['The', 'internet', 'become', 'integral', 'part', 'modern', 'life', ',', 'providing', 'vast', 'array', 'information', 'service', 'fingertip', '.', 'With', 'click', 'tap', ',', 'access', 'news', ',', 'entertainment', ',', 'education', ',', 'communication', ',', 'commerce', 'anywhere', 'world', '.', 'However', ',', 'benefit', 'internet', 'come', 'risk', 'well', ',', 'privacy', 'concern', ',', 'cybercrime', ',', 'misinformation', ',', 'addiction', '.', 'It', 'important', 'individual', 'organization', 'aware', 'risk', 'take', 'measure', 'protect', 'data', 'online', '.', 'By', 'practicing', 'safe', 'online', 'behavior', ',', 'using', 'strong', 'password', ',', 'avoiding', 'suspicious', 'link', ',', 'keeping', 'software', 'up-to-date', ',', 'enjoy', 'benefit', 'internet', 'minimizing', 'risk']\n"
     ]
    }
   ],
   "source": [
    "#lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "\n",
    "print(\"Lemmatization :\", lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': -0.1194857109069052, 'internet': -0.028910849701792363, 'has': 0.0, 'become': 0.0, 'an': 0.0, 'integral': 0.0, 'part': 0.0, 'of': -0.07058938212430264, 'modern': 0.0, 'life,': 0.0, 'providing': 0.0, 'a': -0.012160476851928864, 'vast': 0.0, 'array': 0.0, 'information': 0.0, 'and': -0.1194857109069052, 'services': 0.0, 'at': 0.0, 'our': 0.0, 'fingertips.': 0.0, 'with': -0.012160476851928864, 'just': 0.0, 'few': 0.0, 'clicks': 0.0, 'or': 0.0, 'taps,': 0.0, 'we': -0.012160476851928864, 'can': -0.012160476851928864, 'access': 0.0, 'news,': 0.0, 'entertainment,': 0.0, 'education,': 0.0, 'communication,': 0.0, 'commerce': 0.0, 'from': 0.0, 'anywhere': 0.0, 'in': 0.0, 'world.': 0.0, 'however,': 0.0, 'benefits': -0.012160476851928864, 'come': 0.0, 'risks': -0.028910849701792363, 'as': -0.028910849701792363, 'well,': 0.0, 'such': -0.012160476851928864, 'privacy': 0.0, 'concerns,': 0.0, 'cybercrime,': 0.0, 'misinformation,': 0.0, 'addiction.': 0.0, 'it': 0.0, 'is': 0.0, 'important': 0.0, 'for': 0.0, 'individuals': 0.0, 'organizations': 0.0, 'to': -0.028910849701792363, 'be': 0.0, 'aware': 0.0, 'these': 0.0, 'take': 0.0, 'measures': 0.0, 'protect': 0.0, 'themselves': 0.0, 'their': 0.0, 'data': 0.0, 'online.': 0.0, 'by': 0.0, 'practicing': 0.0, 'safe': 0.0, 'online': 0.0, 'behavior,': 0.0, 'using': 0.0, 'strong': 0.0, 'passwords,': 0.0, 'avoiding': 0.0, 'suspicious': 0.0, 'links,': 0.0, 'keeping': 0.0, 'software': 0.0, 'up-to-date,': 0.0, 'enjoy': 0.0, 'while': 0.0, 'minimizing': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the document\n",
    "words = document.lower().split()\n",
    "\n",
    "# Calculate the TF for each word\n",
    "tf = Counter(words)\n",
    "for key in tf:\n",
    "    tf[key] = tf[key] / float(len(words))\n",
    "\n",
    "# Calculate the IDF for each word\n",
    "num_documents = 1\n",
    "word_documents = {}\n",
    "for word in words:\n",
    "    if word not in word_documents:\n",
    "        word_documents[word] = 1\n",
    "    else:\n",
    "        word_documents[word] += 1\n",
    "idf = {}\n",
    "for word in word_documents:\n",
    "    idf[word] = math.log(num_documents / word_documents[word])\n",
    "\n",
    "# Calculate the TF-IDF for each word\n",
    "tfidf = {}\n",
    "for word in tf:\n",
    "    tfidf[word] = tf[word] * idf[word]\n",
    "\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
